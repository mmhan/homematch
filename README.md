# HomeMatch - Personalized London Property Agent

> A LangChain-powered application that transforms standard London property listings into personalized narratives tailored to individual buyer preferences.

## ğŸ  Project Overview

HomeMatch leverages Large Language Models (LLMs) and vector databases to create personalized London property experiences. The application interprets buyer preferences in natural language and matches them with relevant London properties, generating customized listing descriptions that highlight the most appealing aspects for each potential buyer in the London market.

## âœ¨ Features

- [ ] **Natural Language Preference Processing**: Interpret buyer requirements using LLMs
- [ ] **Semantic Property Search**: Vector-based matching of properties to preferences
- [ ] **Personalized Listing Generation**: Custom descriptions tailored to buyer interests
- [ ] **Multimodal Search** (Advanced): Image and text-based property matching using CLIP
- [ ] **Interactive Preference Collection**: User-friendly preference gathering interface

## ğŸ› ï¸ Technology Stack

- **Framework**: LangChain
- **LLM Provider**: OpenAI GPT
- **Vector Database**: ChromaDB
- **Multimodal AI**: CLIP (Transformers, PyTorch)
- **Development**: Python 3.12, Poetry, Jupyter Notebooks

## ğŸ“‹ Prerequisites

- Python 3.12+
- Poetry (for dependency management)
- OpenAI API Key

## ğŸš€ Installation

```bash
# Clone the repository
git clone <repository-url>
cd homematch

# Install dependencies with Poetry
poetry install

# Activate the virtual environment
poetry shell

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Generate listings (Optional, this will take a while)
poetry run python src/data_generation/generate.py
```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
# Add other configuration variables as needed
```

## ğŸ“– Usage

### Basic Usage

```python
# TODO: Add basic usage examples
```

### Running the Application

```bash
# TODO: Add instructions for running the main application
```

### Using Jupyter Notebooks

```bash
# Start Jupyter
jupyter notebook

# Open the main notebook
# TODO: Add notebook filename
```

## ğŸ“ Project Structure

```
homematch/
â”œâ”€â”€ data/                   # Generated listings and datasets
â”œâ”€â”€ notebooks/              # Jupyter notebooks for development
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_generation/    # LLM-based listing generation
â”‚   â”œâ”€â”€ vector_store/       # Vector database operations
â”‚   â”œâ”€â”€ search/             # Semantic search logic
â”‚   â””â”€â”€ personalization/    # Listing personalization
â”œâ”€â”€ tests/                  # Test files
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ pyproject.toml         # Poetry configuration
â””â”€â”€ README.md              # This file
```

## ğŸ—ï¸ Development Progress

### Step 1: Setting Up the Python Application
- [x] Initialize Poetry project
- [x] Configure dependencies
- [x] Set up development environment

### Step 2: Generating Real Estate Listings
- [x] Create LLM prompts for listing generation
- [x] Generate diverse property listings (minimum 10)

### Step 3: Storing Listings in Vector Database
- [ ] Set up ChromaDB
- [ ] Generate embeddings for listings
- [ ] Store embeddings in vector database

### Step 4: Building User Preference Interface
- [ ] Design preference collection questions
- [ ] Implement preference parsing logic
- [ ] Structure preferences for database queries

### Step 5: Searching Based on Preferences
- [ ] Implement semantic search functionality
- [ ] Fine-tune retrieval algorithms
- [ ] Test search accuracy

### Step 6: Personalizing Listing Descriptions
- [ ] Develop LLM augmentation logic
- [ ] Ensure factual integrity preservation
- [ ] Test personalization quality

### Step 7: Testing and Validation
- [ ] Comprehensive application testing
- [ ] Multiple buyer preference scenarios
- [ ] Performance optimization

### Advanced Features (Optional)
- [ ] CLIP integration for multimodal search
- [ ] Image embedding generation
- [ ] Visual preference matching

## ğŸ§ª Testing

```bash
# Run tests
poetry run pytest

# Run with coverage
poetry run pytest --cov=src
```

## ğŸ“Š Example Outputs

<!-- TODO: Add example inputs and outputs -->

### Sample Buyer Preferences
```python
# TODO: Add example preference inputs
```

### Sample Personalized Listings
```
# TODO: Add example personalized listing outputs
```

## ğŸ¤ Contributing

<!-- TODO: Add contribution guidelines if applicable -->

## ğŸ“ License

<!-- TODO: Add license information -->

## ğŸ”— References

- [LangChain Documentation](https://langchain.readthedocs.io/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [OpenAI API Documentation](https://platform.openai.com/docs)

## ğŸ“ Contact

Mike Myat Min Han - mmhan@indeed.com

---

*This project is part of an AI upskilling initiative focused on practical applications of Large Language Models and Vector Databases.*